{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWGdN7XCSYSm",
        "outputId": "72be0fe0-dfb3-4d54-d8e9-12541c4ebd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 20 13:01:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Using GPU\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('Using GPU')\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  print('CUDA not available. Please connect to a GPU instance if possible.')\n",
        "  device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y6gsK0lGUio"
      },
      "source": [
        "# Get our code and install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOvqzVtiGZxi",
        "outputId": "ed36cbcd-e0a9-40d3-8189-abf608f13d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'XMem'...\n",
            "remote: Enumerating objects: 608, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 608 (delta 240), reused 217 (delta 199), pack-reused 272\u001b[K\n",
            "Receiving objects: 100% (608/608), 269.38 KiB | 848.00 KiB/s, done.\n",
            "Resolving deltas: 100% (352/352), done.\n",
            "/content/XMem\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "Successfully installed numpy-1.26.4\n",
            "Collecting git+https://github.com/cheind/py-thin-plate-spline (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/cheind/py-thin-plate-spline to /tmp/pip-req-build-y45ldbzg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cheind/py-thin-plate-spline /tmp/pip-req-build-y45ldbzg\n",
            "  Resolved https://github.com/cheind/py-thin-plate-spline to commit f6995795397118b7d0ac01aecd3f39ffbfad9dee\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.7.3)\n",
            "Collecting gitpython (from -r requirements.txt (line 3))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hickle (from -r requirements.txt (line 5))\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2->-r requirements.txt (line 1)) (3.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 2)) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r requirements.txt (line 2)) (4.12.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->-r requirements.txt (line 3))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from thinplate==1.0.0->-r requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from thinplate==1.0.0->-r requirements.txt (line 4)) (0.17.1+cu121)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from hickle->-r requirements.txt (line 5)) (3.9.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.0.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 3))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2->-r requirements.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->thinplate==1.0.0->-r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 2)) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 2)) (1.7.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->thinplate==1.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Building wheels for collected packages: thinplate\n",
            "  Building wheel for thinplate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thinplate: filename=thinplate-1.0.0-py3-none-any.whl size=6702 sha256=ccbc4ffda5d102ad19ac0650f808801a84c1e1c7d508a3b73e685f557f069ace\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a86grisp/wheels/3e/f3/84/5780510c4585ad00e08b99a8ae29904185f037823b777af27c\n",
            "Successfully built thinplate\n",
            "Installing collected packages: smmap, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hickle, gitdb, nvidia-cusolver-cu12, gitpython, thinplate\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 hickle-5.0.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 smmap-5.0.1 thinplate-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hkchengrex/XMem.git\n",
        "%cd XMem\n",
        "!pip install opencv-python\n",
        "!pip install -U numpy\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8NrncykF0lo"
      },
      "source": [
        "# Download the pretrained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp63HPm9I2XV",
        "outputId": "b16e92ae-1e0e-4765-df6e-058bb3e3e107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-20 13:03:09--  https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511262077/ea2968ee-04ab-4dee-8596-03319e8c7e9f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240320T130309Z&X-Amz-Expires=300&X-Amz-Signature=e41168ef6712387fd044bd66ca077ca7c7d5a348f0c0da45e5f8633cd80b86cb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511262077&response-content-disposition=attachment%3B%20filename%3DXMem.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-03-20 13:03:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511262077/ea2968ee-04ab-4dee-8596-03319e8c7e9f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240320%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240320T130309Z&X-Amz-Expires=300&X-Amz-Signature=e41168ef6712387fd044bd66ca077ca7c7d5a348f0c0da45e5f8633cd80b86cb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511262077&response-content-disposition=attachment%3B%20filename%3DXMem.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 249026057 (237M) [application/octet-stream]\n",
            "Saving to: ‘./saves/XMem.pth’\n",
            "\n",
            "XMem.pth            100%[===================>] 237.49M   188MB/s    in 1.3s    \n",
            "\n",
            "2024-03-20 13:03:11 (188 MB/s) - ‘./saves/XMem.pth’ saved [249026057/249026057]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P ./saves/ https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_bUsmaYJESK"
      },
      "source": [
        "# Basic setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dot4-UjuJR-w",
        "outputId": "7ed3d25b-ec00-427e-abb2-f2acf83f01ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
            "Single object mode: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 380MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 328MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from os import path\n",
        "from argparse import ArgumentParser\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n",
        "from inference.data.mask_mapper import MaskMapper\n",
        "from model.network import XMem\n",
        "from inference.inference_core import InferenceCore\n",
        "\n",
        "from progressbar import progressbar\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "# default configuration\n",
        "config = {\n",
        "    'top_k': 30,\n",
        "    'mem_every': 5,\n",
        "    'deep_update_every': -1,\n",
        "    'enable_long_term': True,\n",
        "    'enable_long_term_count_usage': True,\n",
        "    'num_prototypes': 128,\n",
        "    'min_mid_term_frames': 5,\n",
        "    'max_mid_term_frames': 10,\n",
        "    'max_long_term_elements': 10000,\n",
        "}\n",
        "\n",
        "network = XMem(config, './saves/XMem.pth').eval().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzq2D_OBM3iP"
      },
      "source": [
        "# Test data\n",
        "\n",
        "Unzip the input.zip (zip with original video and masks) in the XMem folder before proceeding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVyVdpvyThqJ"
      },
      "source": [
        "# Propagate frame-by-frame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def generate_overlay_video(mask_name, video_name):\n",
        "    mask = np.array(Image.open(mask_name))\n",
        "    mask[mask == 255] = 1\n",
        "    print(np.unique(mask))\n",
        "    num_objects = len(np.unique(mask)) - 1\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    processor = InferenceCore(network, config=config)\n",
        "    processor.set_all_labels(range(1, num_objects+1)) # consecutive labels\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    # You can change these two numbers\n",
        "    frames_to_propagate = 200\n",
        "    visualize_every = 1\n",
        "\n",
        "    current_frame_index = 0\n",
        "\n",
        "    # Video writer settings\n",
        "    folder_name = os.path.join('results',video_name.split('.')[0])\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    output_fps = 30\n",
        "    output_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    output_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    output_video_name = os.path.join(folder_name,  \"out-\" + video_name)\n",
        "    output_video_writer = cv2.VideoWriter(output_video_name, cv2.VideoWriter_fourcc(*'mp4v'), output_fps, (output_width, output_height))\n",
        "\n",
        "    with torch.cuda.amp.autocast(enabled=True):\n",
        "        while (cap.isOpened()):\n",
        "            # load frame-by-frame\n",
        "            ret, frame = cap.read()\n",
        "            if not ret or current_frame_index > frames_to_propagate:\n",
        "                break\n",
        "\n",
        "            # convert numpy array to pytorch tensor format\n",
        "            frame_torch, _ = image_to_torch(frame, device=device)\n",
        "            if current_frame_index == 0:\n",
        "                # initialize with the mask\n",
        "                mask_torch = index_numpy_to_one_hot_torch(mask, num_objects+1).to(device)\n",
        "                # the background mask is not fed into the model\n",
        "                prediction = processor.step(frame_torch, mask_torch[1:])\n",
        "            else:\n",
        "                # propagate only\n",
        "                prediction = processor.step(frame_torch)\n",
        "\n",
        "            # argmax, convert to numpy\n",
        "            prediction = torch_prob_to_numpy_mask(prediction)\n",
        "\n",
        "            if current_frame_index % visualize_every == 0:\n",
        "                visualization = overlay_davis(frame, prediction)\n",
        "\n",
        "                # Save mask\n",
        "                name_png = f'out-{mask_name.split(\"-\")[0]}-{str(current_frame_index+1).zfill(3)}.png'\n",
        "                mask_output_name = os.path.join(folder_name, name_png)\n",
        "                # Convert only values equal to 1 to 255 and keep other values unchanged\n",
        "                cv2.imwrite(mask_output_name, (mask == 1).astype(np.uint8) * 255)\n",
        "\n",
        "                # Write frame to output video\n",
        "                output_video_writer.write(cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))\n",
        "                # Display the frame (optional)\n",
        "                # display(Image.fromarray(visualization))\n",
        "\n",
        "            current_frame_index += 1\n",
        "\n",
        "    # Release video capture and writer objects\n",
        "    cap.release()\n",
        "    output_video_writer.release()\n",
        "\n",
        "    return output_video_name"
      ],
      "metadata": {
        "id": "ekWygdbwkDz-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in ['bag', 'bear', 'book', 'swan', 'rhino', 'camel']:\n",
        "  output_video_path = generate_overlay_video(f'{seq}-001.png', f'{seq}.mp4')"
      ],
      "metadata": {
        "id": "PogbLa6RziC0",
        "outputId": "61e0e362-41ce-4ac8-ba57-7fa99f124e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on terminal to zip results folder\n",
        "#zip -r /content/XMem/results.zip /content/XMem/results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Xgpke8EzZn",
        "outputId": "482ce7b4-d47e-4d50-dbc5-be43278e690f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%zip` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "files.download(\"/content/XMem/results.zip\")"
      ],
      "metadata": {
        "id": "WPYQq3uj0me9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1b71f3a7-94a1-46db-d98e-ed43ffb55bc0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_708df5d8-35b9-4686-abc3-ca55dd660a1a\", \"results.zip\", 6132436)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktXQXSANFtQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}